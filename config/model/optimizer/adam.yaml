_target_: torch.optim.Adam             #help='type of optimization class to instantiate'
lr: 1e-4                               #help='initial learning rate'
betas: [0.9, 0.999]                    #help='coefficient used for computing running averages of gradient and its square'
eps: 1e-8                              #help='improve numerical stability'
weight_decay: 0                        #help='weight decay'
amsgrad: False                         #help='enable amsgrad'
